\<div align="center"\>
\<img src="./images/logo.png" alt="icon" width="50px"/\>
\<h1 align="center"\>GPT-API-free / DeepSeek-API-free\</h1\>

Free to use gpt | deepseek / Supports gpt | deepseek | claude | gemini | grok

Domestic dynamic acceleration, direct connection without a proxy, unified protocol for convenient access.

[Quick Start](https://www.google.com/search?q=%23how-to-use) / [API Documentation](https://chatanywhere.apifox.cn/) / [Apply for a Free Internal Test Key](https://api.chatanywhere.org/v1/oauth/free/render) / [Paid Key Support](https://api.chatanywhere.tech/#/shop/) / [Service Availability](https://status.chatanywhere.tech/)

[QQ Group: 599246660](https://qm.qq.com/cgi-bin/qm/qr?k=gmUR-0pW2VxzkXFiGLgvzOa7Ar01y3Vk&jump_from=webapi&authKey=pPr3pz15zNrM7YiaRklsuDafWclmBxQ/PBLf6DdoYo16p6Li0O9T3jXSZVuuzC1K)

[](https://status.chatanywhere.tech/)
[](https://status.chatanywhere.tech/)

[](https://status.chatanywhere.tech/)
[](https://status.chatanywhere.tech/)
[](https://status.chatanywhere.tech/)

\</div\>

## Privacy Statement

This project places a high value on privacy and is committed to protecting the privacy of its users. This project does not collect, record, or store any text entered by users or any text returned by the OpenAI servers in any way. This project does not provide any information about the identity of the API caller to OpenAI or any third party, including but not limited to IP addresses and user agent strings.

However, OpenAI will retain data for 30 days in accordance with its [data usage policy](https://platform.openai.com/docs/data-usage-policies).

## Features

1.  Supports top-ranked large models such as gpt | deepseek | claude | gemini | grok.
2.  The free version supports gpt-4o, gpt-4.1 five times a day; supports deepseek-r1, deepseek-v3 thirty times a day; supports gpt-4o-mini, gpt-3.5-turbo, gpt-4.1-mini, gpt-4.1-nano 200 times a day.
3.  Interface standards are completely consistent with the official ones, compatible with various software/plugins.
4.  Supports streaming responses.
5.  Domestic routes use dynamic acceleration, providing a much better experience than using a proxy to connect to the official servers.
6.  No need for a VPN ("scientific internet access"), directly usable in a domestic environment.
7.  Completely free for personal use.
8.  The protocol uniformly uses the OpenAI standard protocol. For models from other manufacturers, you only need to change the model name, making access convenient.

## üö©Notices

‚ùóÔ∏è*If you encounter no response, errors, etc., you can check [status.chatanywhere.tech](https://status.chatanywhere.tech) to confirm if the service status is normal, which can help troubleshoot the problem.*

‚ùóÔ∏è**Free API Keys are for personal, non-commercial use, education, and non-profit scientific research only. Free API Keys are strictly prohibited for commercial use and for large-scale training of commercial models\! For training research models, please join the QQ group and contact us in advance.**

‚ùóÔ∏èWe will periodically ban keys that are being abused. If you find your key has been mistakenly banned, please contact us through the QQ group.

‚ùóÔ∏èOur system is for internal evaluation and testing purposes only. You assume your own risk for commercial use or use oriented towards the general public.

For the long-term development of this project, the free API Key is limited to a frequency of **200 requests/day/IP & Key** (gpt and embedding are calculated separately, 200 times each). This means if you use multiple keys under one IP, the total number of daily requests for all keys cannot exceed 200; similarly, if you use one key on multiple IPs, the daily number of requests for this key cannot exceed 200. (**The paid version of the API does not have this limitation**)

## Free Use

  - **üöÄ[Apply for a free internal test API Key](https://api.chatanywhere.org/v1/oauth/free/render)**
  - The free version supports deepseek, gpt-3.5-turbo, embedding, gpt-4o-mini, gpt-4o.
  - **Forwarding Host 1: `https://api.chatanywhere.tech` (Domestic relay, lower latency)**
  - **Forwarding Host 2: `https://api.chatanywhere.org` (For use outside of China)**

We will periodically expand capacity based on usage. As long as we are not sanctioned by the officials, we will continue to provide a free API. If this project is helpful to you, please give us a ***Star***. If you encounter problems, you can provide feedback in the [Issues](https://github.com/chatanywhere/GPT_API_free/issues), and we will answer when we have time.

This API Key is used for forwarding the API. You need to change the Host to `api.chatanywhere.tech` (first choice for domestic use) or `api.chatanywhere.org` (for use abroad).

## Paid API

  - Providing a free key purely for public benefit is clearly not a sustainable operating plan. Therefore, we have introduced a paid API Key to cover the daily expenses of the project and promote its healthy cycle. We hope for your understanding.
  - [Purchase a paid Key](https://api.chatanywhere.tech/#/shop/)
  - [Paid Version Price List](https://chatanywhere.apifox.cn/doc-2694962)

<!-- end list -->

1.  Supports a **more stable and faster GPT4 API**. The GPT4 experience is better, usage is unlimited, the price is lower than the official one, and recharging is more convenient.
2.  Billing strategy is the same as the official one. For streaming Q\&A, the tiktoken library is used to accurately calculate Tokens. For non-streaming Q\&A, billing is based directly on the Tokens usage returned by the official API.
3.  The balance does not expire and is permanently valid. According to user feedback, 30 yuan is estimated to last for half a year for an individual with moderate use of gpt-4o-mini.
4.  All interfaces (including the free version) are guaranteed to be forwarded from official OpenAI or Azure interfaces, not unstable solutions like PEO, Plus, or reverse-engineered solutions. No inflation, no adulteration, guaranteeing stability.

## Paid Version Supported Models

| **Model** | **Input** | **Output** | **Supported** | **Features** |
| :--- | :--- | :--- | :--- | :--- |
| o3 | 0.08 / 1K Tokens | 0.32 / 1K Tokens | Yes | Sets a new standard for math, science, coding, vision reasoning tasks, and technical writing. Points to o3-2025-04-16 |
| o3-2025-04-16 | 0.08 / 1K Tokens | 0.32 / 1K Tokens | Yes | Sets a new standard for math, science, coding, vision reasoning tasks, and technical writing. |
| o4-mini | 0.0088 / 1K Tokens | 0.0352 / 1K Tokens | Yes | Sets a new standard for math, science, coding, vision reasoning tasks, and technical writing. Points to o4-mini-2025-04-16 |
| o4-mini-2025-04-16 | 0.0088 / 1K Tokens | 0.0352 / 1K Tokens | Yes | Sets a new standard for math, science, coding, vision reasoning tasks, and technical writing. |
| gpt-4.1 | 0.014 / 1K Tokens | 0.056 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. Points to gpt-4.1-2025-04-14 |
| gpt-4.1-2025-04-14 | 0.014 / 1K Tokens | 0.056 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. |
| gpt-4.1-mini | 0.0028 / 1K Tokens | 0.0112 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. Points to gpt-4.1-mini-2025-04-14 |
| gpt-4.1-mini-2025-04-14 | 0.0028 / 1K Tokens | 0.0112 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. |
| gpt-4.1-nano | 0.0007 / 1K Tokens | 0.0028 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. Points to gpt-4.1-nano-2025-04-14 |
| gpt-4.1-nano-2025-04-14 | 0.0007 / 1K Tokens | 0.0028 / 1K Tokens | Yes | OpenAI's latest model with significant improvements in coding, instruction following, and long context. 1M input, 32k output. |
| gpt-3.5-turbo | 0.0035 / 1K Tokens | 0.0105 / 1K Tokens | Yes | Default model, equivalent to gpt-3.5-turbo-0125 |
| gpt-3.5-turbo-1106 | 0.007 / 1K Tokens | 0.014 / 1K Tokens | Yes | Model updated on November 6, 2023 |
| gpt-3.5-turbo-0125 | 0.0035 / 1K Tokens | 0.0105 / 1K Tokens | Yes | Latest model from January 25, 2024, with the latest data, lower price, faster speed, and fixes for some bugs from the 1106 version. |
| gpt-3.5-turbo-16k | 0.021 / 1K Tokens | 0.028 / 1K Tokens | Yes | Suitable for quick answers to simple questions, more words |
| gpt-3.5-turbo-instruct | 0.0105 / 1K Tokens | 0.014 / 1K Tokens | Yes | Completions model for text generation, providing an accurate natural language processing model not generally needed by average users |
| gpt-4.5-preview | 0.525 / 1K Tokens | 1.05 / 1K Tokens | Yes | OpenAI's latest model, gpt-4.5 |
| gpt-4.5-preview-2025-02-27 | 0.525 / 1K Tokens | 1.05 / 1K Tokens | Yes | OpenAI's latest model, gpt-4.5 |
| o1-mini | 0.021 / 1K Tokens | 0.084 / 1K Tokens | Yes | Reasoning model for complex tasks |
| o1-preview | 0.105 / 1K Tokens | 0.42 / 1K Tokens | Yes | Reasoning model for complex tasks |
| o3-mini [5] | 0.0088 / 1K Tokens | 0.0352 / 1K Tokens | Yes | Reasoning model for complex tasks |
| o1 [5] | 0.12 / 1K Tokens | 0.48 / 1K Tokens | Yes | Reasoning model for complex tasks, the most powerful model to date |
| gpt-4o-search-preview | 0.02125/1K Tokens | 0.085/1K Tokens | Yes | OpenAI's search model, supports web search, points to the latest 4o search model |
| gpt-4o-search-preview-2025-03-11 | 0.02125/1K Tokens | 0.085/1K Tokens | Yes | OpenAI's search model, supports web search |
| gpt-4o-mini-search-preview | 0.001275/1K Tokens | 0.0051 /1K Tokens | Yes | OpenAI's search model, supports web search, points to the latest 4o-mini search model |
| gpt-4o-mini-search-preview-2025-03-11 | 0.001275/1K Tokens | 0.0051 /1K Tokens | Yes | OpenAI's search model, supports web search |
| gpt-4 | 0.21 / 1K Tokens | 0.42 / 1K Tokens | Yes | Default model, equivalent to gpt-4-0613 |
| gpt-4o | 0.0175/1K Tokens + Image fee [2] | 0.07/1K Tokens | Yes | OpenAI's model is cheaper, faster, and smarter, points to the latest 4o version |
| gpt-4o-2024-05-13 | 0.035/1K Tokens + Image fee [2] | 0.105/1K Tokens | Yes | OpenAI's gpt-4o model released on 2024-05-13 |
| gpt-4o-2024-08-06 | 0.0175/1K Tokens + Image fee [2] | 0.07/1K Tokens | Yes | OpenAI's gpt-4o model released on 2024-08-06, supports 128k input, 16k output |
| gpt-4o-2024-11-20 | 0.0175/1K Tokens + Image fee [2] | 0.07/1K Tokens | Yes | OpenAI's gpt-4o model released on 2024-11-20, this model has improved creative writing capabilities‚Äîmore natural, engaging, and targeted writing |
| chatgpt-4o-latest | 0.035/1K Tokens + Image fee [2] | 0.105/1K Tokens | Yes | Dynamically updated version, continuously integrating OpenAI's latest research [4] |
| gpt-4o-mini | 0.00105/1K Tokens + Image fee [2] | 0.0042/1K Tokens | Yes | OpenAI's latest model, lower price, output quality is between 3.5 and 4o, and supports image reading |
| gpt-4-0613 | 0.21 / 1K Tokens | 0.42 / 1K Tokens | Yes | Model updated on June 13, 2023 |
| gpt-4-turbo-preview | 0.07 / 1K Tokens | 0.21 / 1K Tokens | Yes | Latest model, 128K input, max 4K output, knowledge base updated to April 2023. This model always points to the latest preview version of GPT-4. |
| gpt-4-0125-preview | 0.07 / 1K Tokens | 0.21 / 1K Tokens | Yes | Model updated on January 25, 2024, 128K input, max 4K output, knowledge base updated to April 2023, fixes some bugs from the 1106 version. |
| gpt-4-1106-preview | 0.07 / 1K Tokens | 0.21 / 1K Tokens | Yes | Model updated on November 6, 2023, 128K input, max 4K output, knowledge base updated to April 2023. |
| gpt-4-vision-preview | 0.07 / 1K Tokens + Image fee [2] | 0.21 / 1K Tokens | Yes | Multimodal, supports image recognition |
| gpt-4-turbo | 0.07 / 1K Tokens + Image fee [2] | 0.21 / 1K Tokens | Yes | OpenAI's latest multimodal model, supports image recognition, supports function tools |
| gpt-4-turbo-2024-04-09 | 0.07 / 1K Tokens + 0.10115 \* number of images [2] | 0.21 / 1K Tokens | Yes | OpenAI's latest multimodal model, supports image recognition, supports function tools |
| gpt-3.5-turbo-ca | 0.001 / 1K Tokens | 0.003 / 1K Tokens | Yes | Azure OpenAI relay (also a type of official model), cheaper but slower in response |
| gpt-4-ca | 0.12 / 1K Tokens | 0.24 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| gpt-4-turbo-ca | 0.04 / 1K Tokens + 0.0578 \* number of images [3] | 0.12 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| gpt-4o-ca | 0.01 / 1K Tokens + 0.0289 \* number of images [3] | 0.04 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| gpt-4o-mini-ca | 0.00075 / 1K Tokens | 0.003 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| chatgpt-4o-latest-ca | 0.02 / 1K Tokens | 0.06 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| o1-mini-ca | 0.012 / 1K Tokens | 0.048 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| o1-preview-ca | 0.06 / 1K Tokens | 0.24 / 1K Tokens | Yes | Service provided by a third-party premium provider, advantage is the cheap price, but stability is not as good as non-CA. Model return and capabilities are the same. |
| deepseek-reasoner | 0.0036 / 1K Tokens | 0.0144 / 1K Tokens | Yes | Deepseek's Reasoner R1 model. This model is deployed and provided by a third-party supplier, there is a small probability of slow response or errors. |
| deepseek-r1 | 0.0024 / 1K Tokens | 0.0096 / 1K Tokens | Yes | Deepseek's Reasoner R1 model. This model is provided by a third-party (Volcengine) supplier, there is a small probability of slow response or errors. |
| deepseek-v3 | 0.0012 / 1K Tokens | 0.0048 / 1K Tokens | Yes | Deepseek's chat model. This model is provided by a third-party (Volcengine) supplier, there is a small probability of slow response or errors. |
| claude-3-7-sonnet-20250219 | 0.015 / 1K Tokens | 0.075 / 1K Tokens | Yes | Claude's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| claude-3-5-sonnet-20240620 | 0.015 / 1K Tokens | 0.075 / 1K Tokens | Yes | Claude's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| claude-3-5-sonnet-20241022 | 0.015 / 1K Tokens | 0.075 / 1K Tokens | Yes | Claude's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| claude-3-5-haiku-20241022 | 0.005 / 1K Tokens | 0.025 / 1K Tokens | Yes | Claude's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-1.5-flash-latest | 0.0006 / 1K Tokens | 0.0024 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-1.5-pro-latest | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-exp-1206 | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.0-flash-exp | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.0-pro-exp-02-05 | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.0-flash | 0.005 / 1K Tokens | 0.02 / 1K Tokens | Yes | Google Gemini's model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.5-pro-exp-03-25 | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Gemini's latest flagship model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.5-pro-preview-05-06 | 0.01 / 1K Tokens | 0.04 / 1K Tokens | Yes | Gemini's latest flagship model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| gemini-2.5-flash-preview-04-17 | 0.0006 / 1K Tokens | 0.014 / 1K Tokens | Yes | Gemini's latest flagship model. This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| grok-3 | 0.016 / 1K Tokens | 0.08 / 1K Tokens | Yes | Grok basic model (web reverse-engineered version). This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| grok-3-reasoner | 0.016 / 1K Tokens | 0.08 / 1K Tokens | Yes | Reasoning-enhanced model (web reverse-engineered version). This model is provided by a third-party supplier, there is a small probability of slow response or errors. |
| grok-3-deepsearch | 0.016 / 1K Tokens | 0.08 / 1K Tokens | Yes | Deep web search model (web reverse-engineered version). This model is provided by a third-party supplier, there is a small probability of slow response or errors. |

| **Model** | **Price** | **Supported** |
| :--- | :--- | :--- |
| gpt-image-1 | Text input: 0.04CA/1K Tokens, Image input: 0.08CA/1K Tokens, Image input: 0.32 CA/1K Tokens | Yes |
| dall-e-3 1024√ó1024 | 0.280 / image | Yes |
| dall-e-3 1024√ó1792 | 0.560 / image | Yes |
| dall-e-3-hd 1024√ó1024 | 0.560 / image | Yes |
| dall-e-3-hd 1024√ó1792 | 0.840 / image | Yes |
| dall-e-2 1024√ó1024 | 0.14 / image | Yes |
| dall-e-2 512x512 | 0.126 / image | Yes |
| dall-e-2 256x256 | 0.112 / image | Yes |
| tts-1 | 0.105 / 1K characters | Yes |
| tts-1-hd | 0.21 / 1K characters | Yes |
| gpt-4o-mini-tts | (0.12 / minute) + (0.012 / 1kToken) | Yes |
| Whisper | 0.042 / minute | Yes |
| gpt-4o-mini-transcribe | 0.024 / minute | Yes |
| gpt-4o-transcribe | 0.048 / minute | Yes |
| text-embedding-ada-002 | 0.0007 / 1K Tokens | Yes |
| text-embedding-3-small | 0.00014 / 1K Tokens | Yes |
| text-embedding-3-large | 0.00091 / 1K Tokens | Yes |

[1] Tokens: The smallest unit of text data processed in GPT. A token can be a word, a subword, or a character, depending on the language and processing method. For example, in English, a token might be a word like "apple"; in Chinese, a token might be a character like "Ëãπ". 1K Tokens = 1000 Tokens. (Based on experience: gpt-4o model 1000 Tokens ‚âà 1000-1200 Chinese characters; non-gpt-4o models 1000 Tokens ‚âà 700-800 Chinese characters)

[2] How to calculate token usage for multimodal model images, please refer to the official OpenAI documentation: [https://openai.com/api/pricing](https://openai.com/api/pricing). The higher the resolution, the more tokens are used, but it will not exceed 1445 tokens.

[3] For CA series multimodal models, when calculating the price for images, if streaming is used (parameter stream=true), the cost is 0.10115 per image. If non-streaming is used (parameter stream=false), the cost is based on the actual consumption returned by OpenAI. If your image resolution is low, it is usually less than 0.10115. Therefore, we recommend using non-streaming (parameter stream=false) when analyzing images with gpt-4-turbo.

[4] A dynamically updated version that continuously integrates OpenAI's latest research. It provides developers and researchers with the opportunity to explore cutting-edge technologies. Please note that although this model showcases the latest capabilities, for production use, we still recommend choosing an optimized older version of the GPT model to ensure higher stability and performance.

[5] Due to the limited number of available accounts for the o1 and o3-mini models, resource stability may fluctuate, meaning they may be available at times and unavailable at others. It is recommended to implement appropriate fault tolerance when using them in a production environment.

## How to Use

  - Due to frequent malicious requests, we no longer provide public free keys directly. You now need to link your Github account to receive your own free key.
  - üöÄ[Apply for a free internal test API Key](https://api.chatanywhere.org/v1/oauth/free/render) or [Purchase a paid internal test API Key](https://api.chatanywhere.tech/#/shop/)
  - Forwarding Host 1: `https://api.chatanywhere.tech` (Domestic relay, lower latency)
  - Forwarding Host 2: `https://api.chatanywhere.org` (For use outside of China)
  - Balance and usage record query (announcements will also be posted here): [Balance Query & Announcements](https://api.chatanywhere.tech/)
  - The forwarding API cannot directly make requests to the official interface https://www.google.com/search?q=api.openai.com. You need to change the request address to api.chatanywhere.tech to use it. Most plugins and software can be modified.
  - If you encounter problems, go to [ChatAnywhere Status](https://status.chatanywhere.tech/) to check the interface availability.

## Common Software/Plugin Usage Methods

### **python openai official library (using langchain, etc.)**

For sample code, please refer to [demo.py](https://www.google.com/search?q=./demo.py) or the [OpenAI Official Documentation](https://platform.openai.com/docs/guides/text-generation)

***Method One***

```python
from openai import OpenAI

client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key="YOUR API KEY",
    base_url="https://api.chatanywhere.tech/v1"
    # base_url="https://api.chatanywhere.org/v1"
)
```

***Method Two (Use this if Method One doesn't work)***

Modify the environment variable OPENAI\_API\_BASE. Please search for how to change environment variables for your respective system. If it doesn't work after modifying the environment variable, please restart your system.

```bash
OPENAI_API_BASE=https://api.chatanywhere.tech/v1
or OPENAI_API_BASE=https://api.chatanywhere.org/v1
```

### **Open-source gpt\_academic**

Find the `API_URL_REDIRECT` configuration in the `config.py` file and modify it to the following:

```python
API_URL_REDIRECT = {"https://api.openai.com/v1/chat/completions": "https://api.chatanywhere.tech/v1/chat/completions"}
# API_URL_REDIRECT = {"https://api.openai.com/v1/chat/completions": "https://api.chatanywhere.org/v1/chat/completions"}
```

### **Gomoon (Supports reading files, building knowledge bases, recommended)**

Gomoon is an open-source desktop large model application that supports Mac and Windows platforms. It additionally supports parsing files, images, local knowledge bases, etc.

Official Website: [https://gomoon.top](https://gomoon.top)

GitHub Address: [https://github.com/wizardAEI/Gomoon](https://github.com/wizardAEI/Gomoon)

How to use: Enter the Gomoon settings page (top right corner of the page), fill in the key in the settings as shown in the picture, and set the proxy to `https://api.chatanywhere.tech/v1`

### **Zotero plugin zotero-gpt**

Supports AI-powered paper reading, a research artifact.

Download link: https://github.com/MuiseDestiny/zotero-gpt/releases (Download the latest version of the zotero-gpt.xpi file)

**Zotero 7 Usage (Recommended to use Zotero 7)**

1.  Install the plugin

    After downloading the plugin from the link (for Zotero 7, you should download version 1.0 or above), click on Tools -\> Add-ons in the top left corner of Zotero.

    Click Install Add-on From File

    Find the zotero-gpt.xpi you downloaded and install it.

2.  Configure the plugin

    Click on Edit -\> Preferences in the top left corner of Zotero.

    Then set it up as shown in the picture.

**Zotero 6 Usage**

After installing the plugin, use the following commands to set it up:

```
/api https://api.chatanywhere.tech

/secretKey your_purchased_forwarding_key remember not to forget sk-

# Command to switch models
/model gpt-3.5-turbo-0125 
```

### **Zotero translation plugin zotero-pdf-translate**

Download link: https://github.com/windingwind/zotero-pdf-translate/releases

Fill in the interface address: https://api.chatanywhere.tech/v1/chat/completions

Don't worry about whether the status shows as available. Just fill it in and it will work.

### **BotGem(AMA)**

ChatGPT desktop application, supports all platforms, ***supports gpt-4-vision***.

Download link: https://bytemyth.com/ama

How to use: After downloading and installing, go to settings and set it up as shown in the picture, then click update.

### **ChatBox**

Open-source ChatGPT desktop application, supports all desktop platforms.

Download link: [https://github.com/Bin-Huang/chatbox/releases](https://github.com/Bin-Huang/chatbox/releases)

How to use: Fill in the purchased key in the settings as shown in the picture, and set the proxy to `https://api.chatanywhere.tech`

### **Browser plugin ChatGPT Sidebar**

Official website link: [https://chatgpt-sidebar.com/](https://chatgpt-sidebar.com/)

After installing the plugin, enter the settings page, modify the settings as shown, and change the url to `https://api.chatanywhere.tech`.

### **Jetbrains plugin ChatGPT - Easycode**

\<img src="./images/jet1.png" width='200'/\>

After installing the plugin, configure it in Settings \> Tools \> OpenAI \> GPT 3.5 Turbo as shown in the picture. The key is to change the Server Settings to `https://api.chatanywhere.tech/v1/chat/completions` and check Customize Server.

[](https://www.star-history.com/#chatanywhere/GPT_API_free&Date)
